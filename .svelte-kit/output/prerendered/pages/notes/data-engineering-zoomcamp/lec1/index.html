<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link href="../../../_app/immutable/assets/0.CnhQzyL0.css" rel="stylesheet">
		<link rel="modulepreload" href="../../../_app/immutable/entry/start.C43cdrKu.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/Cf-iAI25.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/BE8cp4uu.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/D0iwhpLH.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/Lp0pb3Tn.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/BRX--utR.js">
		<link rel="modulepreload" href="../../../_app/immutable/entry/app.H3ukDrf1.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/BxqDlgHp.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/CactJclj.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/BUhI7Qyb.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/CCM6-gPc.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/BXkG0FcK.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/B58ZsqZY.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/D9W1QFau.js">
		<link rel="modulepreload" href="../../../_app/immutable/nodes/0.CMhegQeJ.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/COomv8M5.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/BwvfVqQf.js">
		<link rel="modulepreload" href="../../../_app/immutable/chunks/Ce9mPtEv.js">
		<link rel="modulepreload" href="../../../_app/immutable/nodes/5.q35MWTQo.js"><!--12qhfyh--><link rel="icon" href="data:image/png;base64,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"/> <meta name="viewport" content="width=device-width, initial-scale=1"/><!----><!--om9p7w--><!----><title>Docker TerraForm and SQL</title>
	</head>

	<body data-sveltekit-preload-data="hover">
		<div style="display: contents"><!--[--><!--[--><!----><div class="app-shell svelte-12qhfyh"><button class="menu-toggle svelte-12qhfyh" aria-label="Toggle Menu">☰</button> <nav class="svelte-12qhfyh"><h3 class="svelte-12qhfyh"><a href="../../../" class="svelte-12qhfyh">Knowledge Base</a></h3> <div class="category"><ul class="svelte-12qhfyh"><li class="svelte-12qhfyh"><a href="../../../graph" class="svelte-12qhfyh">Graph View</a></li></ul></div> <!--[--><div class="category"><p class="category-title svelte-12qhfyh"><strong>PYTHON-REFRESHER</strong></p> <ul class="svelte-12qhfyh"><!--[--><li class="svelte-12qhfyh"><a href="../../../notes/python-refresher/Functional Programming" class="svelte-12qhfyh">Functional Programming In Python</a></li><li class="svelte-12qhfyh"><a href="../../../notes/python-refresher/regex" class="svelte-12qhfyh">Regular Expressions</a></li><li class="svelte-12qhfyh"><a href="../../../notes/python-refresher/Object Oriented Programming in Python" class="svelte-12qhfyh">Object Oriented Programming In Python</a></li><li class="svelte-12qhfyh"><a href="../../../notes/python-refresher/Python From Scratch" class="svelte-12qhfyh">Python from Scratch</a></li><!--]--></ul></div><div class="category"><p class="category-title svelte-12qhfyh"><strong>100XDEVS</strong></p> <ul class="svelte-12qhfyh"><!--[--><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/typescript" class="svelte-12qhfyh">Typescript</a></li><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/recoil" class="svelte-12qhfyh">State Management using Recoil</a></li><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/mongo-in-depth" class="svelte-12qhfyh">MongoDB in Depth</a></li><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/dom" class="svelte-12qhfyh">Document Object Model</a></li><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/react" class="svelte-12qhfyh">React</a></li><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/backend-basics-2" class="svelte-12qhfyh">Middlewares, Global Catches, Data Validation and Auth Basics</a></li><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/JS-Fundamentals" class="svelte-12qhfyh">Javascript Fundamentals</a></li><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/backend-basics" class="svelte-12qhfyh">Express , Backend, Authentication , JWT</a></li><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/taste is the new moat" class="svelte-12qhfyh">Taste is the New Moat - Building Winterfell</a></li><li class="svelte-12qhfyh"><a href="../../../notes/100xdevs/html-css-fundamentals" class="svelte-12qhfyh">HTML,CSS Fundamentals for learning web dev</a></li><!--]--></ul></div><div class="category"><p class="category-title svelte-12qhfyh"><strong>PROJECTS</strong></p> <ul class="svelte-12qhfyh"><!--[--><li class="svelte-12qhfyh"><a href="../../../notes/projects/realtime-data-streaming" class="svelte-12qhfyh">Realtime Data Streaming</a></li><li class="svelte-12qhfyh"><a href="../../../notes/projects/knowl" class="svelte-12qhfyh">knowledge discovery and search on your data!</a></li><li class="svelte-12qhfyh"><a href="../../../notes/projects/kai" class="svelte-12qhfyh">Building a Small AI Agent from Scratch - Kai</a></li><!--]--></ul></div><div class="category"><p class="category-title svelte-12qhfyh"><strong>AI-ML-BOOTCAMP</strong></p> <ul class="svelte-12qhfyh"><!--[--><li class="svelte-12qhfyh"><a href="../../../notes/ai-ml-bootcamp/transformers" class="svelte-12qhfyh">Coding and Understanding Transformers from Scratch</a></li><li class="svelte-12qhfyh"><a href="../../../notes/ai-ml-bootcamp/neural-networks-from-scratch" class="svelte-12qhfyh">Neural Networks from Scratch</a></li><li class="svelte-12qhfyh"><a href="../../../notes/ai-ml-bootcamp/catching-upto-transformers" class="svelte-12qhfyh">Fast Tracking the Course of AI</a></li><!--]--></ul></div><div class="category"><p class="category-title svelte-12qhfyh"><strong>DATA-ENGINEERING-ZOOMCAMP</strong></p> <ul class="svelte-12qhfyh"><!--[--><li class="svelte-12qhfyh"><a href="../../../notes/data-engineering-zoomcamp/lec1" class="svelte-12qhfyh">Docker TerraForm and SQL</a></li><li class="svelte-12qhfyh"><a href="../../../notes/data-engineering-zoomcamp/Shells and Terminals" class="svelte-12qhfyh">Learn Shells and Terminals</a></li><li class="svelte-12qhfyh"><a href="../../../notes/data-engineering-zoomcamp/ddia/reliable-scalable-maintainable-applications" class="svelte-12qhfyh">Reliable, Scalable and Maintainable Applications</a></li><!--]--></ul></div><div class="category"><p class="category-title svelte-12qhfyh"><strong>SVELTE-NOTES</strong></p> <ul class="svelte-12qhfyh"><!--[--><li class="svelte-12qhfyh"><a href="../../../notes/svelte-notes/svelte-events" class="svelte-12qhfyh">Svelte Events</a></li><li class="svelte-12qhfyh"><a href="../../../notes/svelte-notes/svelte-logic" class="svelte-12qhfyh">Svelte Logic</a></li><li class="svelte-12qhfyh"><a href="../../../notes/svelte-notes/svelte-props" class="svelte-12qhfyh">Svelte Props</a></li><li class="svelte-12qhfyh"><a href="../../../notes/svelte-notes/svelte-reactivity" class="svelte-12qhfyh">Svelte Reactivity</a></li><li class="svelte-12qhfyh"><a href="../../../notes/svelte-notes/skeleton of svelte projects" class="svelte-12qhfyh">Skeleton of Svelte Projects</a></li><li class="svelte-12qhfyh"><a href="../../../notes/svelte-notes/svelte-basics" class="svelte-12qhfyh">Svelte Basics</a></li><li class="svelte-12qhfyh"><a href="../../../notes/svelte-notes/sveltekit" class="svelte-12qhfyh">SvelteKit Notes</a></li><!--]--></ul></div><!--]--></nav> <main class="svelte-12qhfyh"><!----><section><h1 class="title">Docker TerraForm and SQL</h1> <p class="subtitle">1/18/26</p> <!----><h3>Difference b/w an Data Engineer and and AI Engineer</h3> <ul><li>Data Engineer -> making sure all the data is captured, ready for analysis , clean and can be used.</li> <li>AI Engineer -> work on the AI aspect of the product , do prompt tuning, validate your model, verifiable rewards etc.</li></ul> <h3>Docker For Data Engineering:</h3> <ul><li>Docker is a way to separate what we have in our host machine and the application (that requires other software dependencies).</li> <li>What we have in Docker container is completely isolated from host machine.</li> <li>What we run has no effect from the host machine and has no effect from the host machine.</li> <li>Simplest Docker Command to check if Docker installed correctly: <ul><li><code>docker run hello-world</code></li> <li>Can run with interactive terminal as <code>docker run -it ubuntu</code> <ul><li>Whatever we do here is isolated from the host machine</li></ul></li> <li>To come back we do <code>docker run -it ubuntu</code></li> <li>But when we do this , the problem is the command is then not found.</li></ul></li> <li>Everytime we create an docker container from an Docker image. <ul><li>An instance of the Docker image is created -> it contains a complete snapshot of the operating system.</li> <li><img src="/images/migrated/data-engineering-zoomcamp/imgs/Screenshot%202026-01-18%20at%2011.48.05%20AM.png" alt="Screenshot 2026-01-18 at 11.48.05 AM.png"/></li> <li>It is stateless and doesn’t preserve the state.</li> <li>Instead of Ubuntu we can also use the direct python image of 3.13 directly also.</li></ul></li> <li>When installing the Python 3.13 image : <ul><li>python -> image name</li> <li>3.13.11-slim -> is the tag name</li></ul></li> <li>If we wanted the entry point to be a bash session and not python repl directly: <ul><li><code>docker run -it --entrypoint=bash python:3.13.11-slim</code></li></ul></li> <li>We can see stopped containers (which are saved somewhere as) <ul><li><code>docker ps -a</code></li> <li>even if we do <code>rm -rf /</code></li> <li>lists all the docker images that we executed and they have all the state</li> <li>can remove all the files as <code>docker ps -aq</code> -> gets the id <ul><li>then run as `<code>docker rm</code>docker ps -aq<code></code></li></ul></li></ul></li> <li>How to preserve state ? <ul><li>let us have a dir <code>test</code> and it contains files in that directory</li> <li>what if we need to have access to the files from our docker container ?</li></ul></li> <li>Executing a file from inside volumes: <ul><li>We have a folder <code>test/</code> that should be available for both host machine and the container.</li> <li>Using volume mapping as : <code>docker run -it --entrypoint=bash -v $(pwd)/test:/app/test python:3.13.11-slim</code></li> <li>where <code>$(pwd)/test/</code> is the local fs directory where it is kept</li> <li>and <code>/app/test</code> is where it is being mapped to in Docker.</li> <li>remember this should be executed from <code>$(pwd)</code> and not inside from <code>$(pwd)/test</code></li></ul></li></ul> <h3>Data Pipelines:</h3> <ul><li>A data pipeline is a service that receives data as input and outputs more data.</li> <li>Eg: reading a CSV file, transforming the data somehow and storing it as a table in a PostgreSQL database.</li> <li><img src="/images/migrated/data-engineering-zoomcamp/imgs/Screenshot%202026-01-18%20at%201.17.04%20PM.png" alt="Screenshot 2026-01-18 at 1.17.04 PM.png"/></li> <li>We have CSV files and parses the CSV files and creates the parquert files -> takes in some input and produces some output.</li> <li>Anything that can take data from one and put in some destination is called a data pipeline.</li></ul> <h4>Building a basic pipeline in <code>pipeline/pipeline.py</code>:</h4> <ul><li>arguments to check data in month 12 using the sys module</li> <li>using pandas to then visualize the data in the given month</li> <li>then saving the data to parquet -> parquet is a binary format for data. optimized for csv</li> <li>want a isolated environment for setting up pyarrow and parquet.</li> <li>create an virtual environment for the environment , different from the virtual environment we have for the docker image.</li> <li>easier to isolate one project from another</li> <li><img src="/images/migrated/data-engineering-zoomcamp/imgs/Screenshot%202026-01-18%20at%201.35.58%20PM.png" alt="Screenshot 2026-01-18 at 1.35.58 PM.png"/></li> <li>using uv to manage creating virtual environments <ul><li><code>uv init --python 3.13</code></li> <li>it creates its own python and it will use the uv’s python to manage the project and to add the dependencies.</li></ul></li> <li>now we create an new docker image , python 3.13 , pyarrow, pandas and when we run docker , we run this pipeline.py</li> <li><code>Dockerfile</code> is a special file that tells how we are gonna create the Docker container.</li> <li>Run as `docker build -t test:pandas . <ul><li><code>-t</code> is the tag name that we need to pass</li> <li><code>.</code> is the directory we are targetting ; where Dockerfile is specifically</li> <li>Then can run as <code>docker run -it --entrypoint=bash --rm test:pandas</code> <ul><li>when we finish the docker sessions, we wont have the state saved somewhere</li> <li>no have any dangling things left</li></ul></li> <li>Using <code>ENTRYPOINT</code> we can redefine where we want it to run it from next time. <ul><li><code>docker run -it --rm test:pandas 12</code></li></ul></li> <li>in our local machine we used <code>uv</code> but in our docker image we didnt. <ul><li>update our docker image  to copy from the host system to the docker image</li> <li><code>COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/</code></li> <li>after doing this uv becomes available.</li> <li>after copying this we run <code>RUN uv sync --locked</code> to have the same dependencies on the docker container</li> <li>so the python env in our local and in docker will exactly will be the same.</li> <li>we can pass the uv run command in the entrypoint</li> <li>or better to use it in the env path</li> <li><code>ENV PATH="/code/.venv/bin:$PATH"</code></li></ul></li></ul></li></ul> <h4>Adding Postgres to our flow:</h4> <ul><li>Docker can help with specific version of Postgres for our setup.</li> <li>Setting up basic postgres on docker:</li> <li><code>docker run -it --rm -e POSTGRES_USER="root" -e POSTGRES_PASSWORD="root" -e POSTGRES_DB="my_taxi" -v ny_taxi_postgres_data:/var/lib/postgresql -p 5432:5432 postgres:18</code></li> <li><code>-e</code> flag are used to setup env variables</li> <li>for postgres we are configuring it with a user , password and database name.</li> <li>this is different from every container , the potential variables can be used.</li> <li><code>ny_taxi_postgres_data</code> will be a inner volume for Docker that we will not be able to see <ul><li>with it we can preserve our data</li> <li>we can put whatever data that we want , and save it and next time it would be there</li> <li>The concept is the same with <strong>volume mapping</strong> <ul><li>we have a host machine and we map it to a container</li></ul></li> <li>With <strong>port mapping</strong> <ul><li>we have a port in host machine and we map it to a port in the container.</li> <li>we sent a request to <code>localhost:5432</code> , is actually sent to whatever is running to inside in the container.</li></ul></li> <li>pgcli <ul><li>python tool to intertact with postgres</li> <li>adding it as a dev dependency to the uv project.</li> <li>not a main dependency, using this dependency to just interaction with dev,not dependent on production use case.</li> <li><code>uv run pgcli -h localhost -p 5432 -u root -d ny_taxi</code></li></ul></li></ul></li> <li>Flow of things till now : <ul><li><img src="/images/migrated/data-engineering-zoomcamp/imgs/Screenshot%202026-01-18%20at%207.01.38%20PM.png" alt="Screenshot 2026-01-18 at 7.01.38 PM.png"/></li></ul></li> <li>Even if we disconnect from it now, it will still have all the data till now.</li></ul> <h4>Interactive Analysis of Our Data using Jupyter</h4> <ul><li>adding <code>jupyter</code> as a dev dependency to see and analyze the data into a jupyter notebook and to see the dependency.</li> <li>we want to use pandas to read a csv file — which is present in remote — nyt taxi dataset , which is in parquet.</li> <li>useful engineering tip -> added the prefix to set the main route to download from and url to point to specific dataset we want <ul><li>then use <code>pd.read_csv()</code> to download the specific url</li> <li>can then look at the data using <code>df.head()</code></li> <li>now our goal is to put this data into postgres.</li> <li>parquet also schemas in the datatype, but csv doesnt</li> <li>so pandas is trying to infer this type somehow</li> <li>so we use a custom datatype , so to remove the type not matching warning</li> <li><pre class="shiki vesper" style="background-color:#101010;color:#FFF"><code><span class="line"><span style="color:#FFF">	  dtype </span><span style="color:#A0A0A0">=</span><span style="color:#FFF"> {</span></span>
<span class="line"><span style="color:#99FFE4">    "VendorID"</span><span style="color:#FFF">: </span><span style="color:#99FFE4">"Int64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "passenger_count"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"Int64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "trip_distance"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"float64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "RatecodeID"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"Int64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "store_and_fwd_flag"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"string"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "PULocationID"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"Int64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "DOLocationID"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"Int64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "payment_type"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"Int64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "fare_amount"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"float64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "extra"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"float64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "mta_tax"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"float64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "tip_amount"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"float64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "tolls_amount"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"float64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "improvement_surcharge"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"float64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "total_amount"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"float64"</span><span style="color:#FFF">,</span></span>
<span class="line"><span style="color:#99FFE4">    "congestion_surcharge"</span><span style="color:#FFF">:</span><span style="color:#99FFE4">"float64"</span></span>
<span class="line"><span style="color:#FFF">}</span></span></code></pre></li> <li>to add this in our postgres , we would need an ORM :<code>sqlalchemy</code> and also the <code>psyciog2-binary</code> which is the postgres driver for python.</li> <li>first we create an engine in our jupyter notebook to ingest the data.</li> <li><pre class="shiki vesper" style="background-color:#101010;color:#FFF"><code><span class="line"><span style="color:#A0A0A0">from</span><span style="color:#FFF"> sqlalchemy </span><span style="color:#A0A0A0">import</span><span style="color:#FFF"> create_engine</span></span>
<span class="line"><span style="color:#FFF">engine </span><span style="color:#A0A0A0">=</span><span style="color:#FFF"> create_engine(</span><span style="color:#99FFE4">"postgresql://root:root@localhost:5432/ny_taxi"</span><span style="color:#FFF">)</span></span></code></pre> <ul><li>add the schema only (without inserting data)</li> <li><pre class="shiki vesper" style="background-color:#101010;color:#FFF"><code><span class="line"><span style="color:#FFF">df.head(</span><span style="color:#FFC799">0</span><span style="color:#FFF">).to_sql(name</span><span style="color:#A0A0A0">=</span><span style="color:#99FFE4">'yellow_taxi_data'</span><span style="color:#FFF">,con</span><span style="color:#A0A0A0">=</span><span style="color:#FFF">engine,if_exists</span><span style="color:#A0A0A0">=</span><span style="color:#99FFE4">'replace'</span><span style="color:#FFF">)</span></span></code></pre></li></ul></li></ul></li> <li>now to save this data into postgres , we should save them in chunks , otherwise the datasets could be huge and we dont want to load them up in memory.</li> <li>we define an iterator : <ul><li><pre class="shiki vesper" style="background-color:#101010;color:#FFF"><code><span class="line"><span style="color:#FFF">df_iter </span><span style="color:#A0A0A0">=</span><span style="color:#FFF"> pd.read_csv(url,dtype</span><span style="color:#A0A0A0">=</span><span style="color:#FFF">dtype,parse_dates</span><span style="color:#A0A0A0">=</span><span style="color:#FFF">parse_dates,</span></span>
<span class="line"><span style="color:#FFF">iterator</span><span style="color:#A0A0A0">=</span><span style="color:#FFF">True,chunksize</span><span style="color:#A0A0A0">=</span><span style="color:#FFC799">100000</span><span style="color:#FFF">)</span></span></code></pre></li> <li>and then using a for loop we can iterate and push the data into the database.</li></ul></li> <li>can then insert and check progress using <code>tqdm</code> <ul><li><pre class="shiki vesper" style="background-color:#101010;color:#FFF"><code><span class="line"><span style="color:#A0A0A0">for</span><span style="color:#FFF"> df_chunk </span><span style="color:#A0A0A0">in</span><span style="color:#FFF"> tqdm(df_iter):</span></span>
<span class="line"><span style="color:#FFF">df_chunk.to_sql(name</span><span style="color:#A0A0A0">=</span><span style="color:#99FFE4">'yellow_taxi_data'</span><span style="color:#FFF">,con</span><span style="color:#A0A0A0">=</span><span style="color:#FFF">engine,if_exists</span><span style="color:#A0A0A0">=</span><span style="color:#99FFE4">'append'</span><span style="color:#FFF">)</span></span></code></pre></li></ul></li></ul> <h4>Optimized Data Ingestion</h4> <ul><li>generate a script from the jupyter notebook and create an ingestion pipeline</li> <li>refactored into clean ingestion pipeline that can be run with a single command. <ul><li><code>python pipeline/ingest_data.py</code></li></ul></li></ul> <h4>Making a Better command line interface using click</h4> <ul><li>Using <code>click</code> to make a better command line interface to use our parameters to get the data and make it better.</li></ul> <h4>Architecture till now:</h4> <ul><li><img src="/images/migrated/data-engineering-zoomcamp/imgs/Screenshot%202026-01-18%20at%209.46.25%20PM.png" alt="Screenshot 2026-01-18 at 9.46.25 PM.png"/></li> <li>when we try to connect to the localhost , it is trying to connect to the localhost internally to docker not to our local.</li> <li>need to create using <code>docker network</code></li> <li>things within the same network can see each other. <ul><li><code>pgdatabase</code> in <code>postgres:18</code> container</li> <li><code>taxi_ingest:v001</code> in <code>ingest</code> container</li> <li><img src="/images/migrated/data-engineering-zoomcamp/imgs/Screenshot%202026-01-18%20at%209.53.50%20PM.png" alt="Screenshot 2026-01-18 at 9.53.50 PM.png"/></li> <li>they can then see each other and can also access ports of each other.</li> <li>after resolving this, we added pgAdmin to run in the same network to get a better UI.</li> <li>After adding pgadmin: <ul><li><img src="/images/migrated/data-engineering-zoomcamp/imgs/Screenshot%202026-01-18%20at%2010.04.45%20PM.png" alt="Screenshot 2026-01-18 at 10.04.45 PM.png"/></li></ul></li></ul></li></ul> <h4>docker-compose</h4> <ul><li>to execute both the services db up and setup pgAdmin together.</li> <li>creates volumes and networks</li></ul> <h3>SQL Refresher</h3> <ul><li></li></ul><!----><!----></section><!----><!----></main> <!--[!--><!--]--></div><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_b257i5 = {
						base: new URL("../../..", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("../../../_app/immutable/entry/start.C43cdrKu.js"),
						import("../../../_app/immutable/entry/app.H3ukDrf1.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 5],
							data: [{type:"data",data:{menu:{"python-refresher":[{title:"Functional Programming In Python",tags:["functional-programming","python"],slug:"python-refresher/Functional Programming",category:"python-refresher",date:"2026-02-19T15:55:43.702Z"},{title:"Regular Expressions",tags:["regex","python"],date:"2026-02-15T05:00:00.000Z",slug:"python-refresher/regex",category:"python-refresher"},{title:"Object Oriented Programming In Python",tags:["python","oop","basic-programming"],date:"2025-03-01T05:00:00.000Z",slug:"python-refresher/Object Oriented Programming in Python",category:"python-refresher"},{title:"Python from Scratch",tags:["basic-programming","python"],date:"2024-12-28T05:00:00.000Z",slug:"python-refresher/Python From Scratch",category:"python-refresher"}],"100xdevs":[{title:"Typescript",tags:["typescript","100xdevs"],date:"2026-02-17T05:00:00.000Z",slug:"100xdevs/typescript",category:"100xdevs"},{title:"State Management using Recoil",tags:["react","state-management","recoil"],date:"2026-02-15T05:00:00.000Z",slug:"100xdevs/recoil",category:"100xdevs"},{title:"MongoDB in Depth",tags:["100xdevs","dbs","mongodb"],date:"2026-01-26T05:00:00.000Z",slug:"100xdevs/mongo-in-depth",category:"100xdevs"},{title:"Document Object Model",tags:["DOM","100xdevs","frontend"],date:"2026-01-22T05:00:00.000Z",slug:"100xdevs/dom",category:"100xdevs"},{title:"React",tags:["react","100xdevs","frontend"],date:"2026-01-22T05:00:00.000Z",slug:"100xdevs/react",category:"100xdevs"},{title:"Middlewares, Global Catches, Data Validation and Auth Basics",tags:["middlewares","zod","jwt"],date:"2026-01-21T05:00:00.000Z",slug:"100xdevs/backend-basics-2",category:"100xdevs"},{title:"Javascript Fundamentals",tags:["projects","javascript","100xdevs"],date:"2026-01-19T05:00:00.000Z",slug:"100xdevs/JS-Fundamentals",category:"100xdevs"},{title:"Express , Backend, Authentication , JWT",tags:["express","backend","nodejs"],date:"2026-01-19T05:00:00.000Z",slug:"100xdevs/backend-basics",category:"100xdevs"},{title:"Taste is the New Moat - Building Winterfell",tags:["css","design","100xdevs"],date:"2026-01-19T05:00:00.000Z",slug:"100xdevs/taste is the new moat",category:"100xdevs"},{title:"HTML,CSS Fundamentals for learning web dev",tags:["100xdevs","html","css"],date:"2026-01-13T05:00:00.000Z",slug:"100xdevs/html-css-fundamentals",category:"100xdevs"}],projects:[{title:"Realtime Data Streaming",tags:["data-engineering","streaming","realtime-data-streaming"],date:"2026-02-08T05:00:00.000Z",slug:"projects/realtime-data-streaming",category:"projects"},{title:"knowledge discovery and search on your data!",tags:["search","knowl","ai","llms"],date:"2026-02-05T05:00:00.000Z",slug:"projects/knowl",category:"projects"},{title:"Building a Small AI Agent from Scratch - Kai",tags:["ai","agentic-loop","claude-code"],date:"2026-01-27T05:00:00.000Z",slug:"projects/kai",category:"projects"}],"ai-ml-bootcamp":[{title:"Coding and Understanding Transformers from Scratch",tags:["100xdevs","transformers","ai"],date:"2026-02-03T05:00:00.000Z",slug:"ai-ml-bootcamp/transformers",category:"ai-ml-bootcamp"},{title:"Neural Networks from Scratch",tags:["100xdevs","ai","nlp","neural-networks"],date:"2026-01-24T05:00:00.000Z",slug:"ai-ml-bootcamp/neural-networks-from-scratch",category:"ai-ml-bootcamp"},{title:"Fast Tracking the Course of AI",tags:["ai","nlp","transformers","100xdevs"],date:"2026-01-23T05:00:00.000Z",slug:"ai-ml-bootcamp/catching-upto-transformers",category:"ai-ml-bootcamp"}],"data-engineering-zoomcamp":[{title:"Docker TerraForm and SQL",tags:["data-engineering","terraform","sql"],date:"2026-01-18T05:00:00.000Z",slug:"data-engineering-zoomcamp/lec1",category:"data-engineering-zoomcamp"},{title:"Learn Shells and Terminals",tags:["boot-dev","basic-programming","shell-utilities"],date:"2025-02-01T05:00:00.000Z",slug:"data-engineering-zoomcamp/Shells and Terminals",category:"data-engineering-zoomcamp"},{title:"Reliable, Scalable and Maintainable Applications",tags:["ddia","scalable-applications","maintainibility"],date:"2025-01-13T05:00:00.000Z",slug:"data-engineering-zoomcamp/ddia/reliable-scalable-maintainable-applications",category:"data-engineering-zoomcamp"}],"svelte-notes":[{title:"Svelte Events",tags:["svelte","ui","frontend","DOM"],date:"2025-07-31T04:00:00.000Z",slug:"svelte-notes/svelte-events",category:"svelte-notes"},{title:"Svelte Logic",tags:["svelte","frontend","ui","ui-logic","conditional-rendering"],date:"2025-07-26T04:00:00.000Z",slug:"svelte-notes/svelte-logic",category:"svelte-notes"},{title:"Svelte Props",date:"2025-07-26T04:00:00.000Z",tags:["frontend","svelte","ui","props","state"],slug:"svelte-notes/svelte-props",category:"svelte-notes"},{title:"Svelte Reactivity",date:"2025-07-25T04:00:00.000Z",tags:["svelte","frontend","reactivity","svelte-basics","ui"],slug:"svelte-notes/svelte-reactivity",category:"svelte-notes"},{title:"Skeleton of Svelte Projects",tags:["svelte","ui","npm"],date:"2025-05-31T04:00:00.000Z",slug:"svelte-notes/skeleton of svelte projects",category:"svelte-notes"},{title:"Svelte Basics",tags:["frontend","svelte","ui","svelte-basics"],date:"2025-05-31T04:00:00.000Z",slug:"svelte-notes/svelte-basics",category:"svelte-notes"},{title:"SvelteKit Notes",tags:["svelte","ui","frontend"],date:"2025-05-31T04:00:00.000Z",slug:"svelte-notes/sveltekit",category:"svelte-notes"}]}},uses:{}},null],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
